{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"C:/Projects/TFM/dataset/AD_MCI_HC_WINDOWED\"\n",
    "INDEX_PATH = \"C:/Projects/TFM/dataset/AD_MCI_HC_WINDOWED/data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from entities.graphs.graph_builder import RawAndPearson, MomentsAndPearson\n",
    "from entities.graphs.data_reader import read_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataset(Dataset):\n",
    "    def __init__(self, indices ,builder, transform=None, target_transform=None):\n",
    "        self.indices = indices\n",
    "        self.builder = builder\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        current_path = self.indices.iloc[idx][\"path\"]\n",
    "        raw_data = read_record(current_path)\n",
    "        label = self.indices.iloc[idx][\"label\"]\n",
    "        data = self.builder.build(raw_data, label)\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>C:\\Projects\\TFM\\dataset\\AD_MCI_HC_WINDOWED\\AD\\...</td>\n",
       "      <td>AD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2407</th>\n",
       "      <td>C:\\Projects\\TFM\\dataset\\AD_MCI_HC_WINDOWED\\AD\\...</td>\n",
       "      <td>AD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8716</th>\n",
       "      <td>C:\\Projects\\TFM\\dataset\\AD_MCI_HC_WINDOWED\\HC\\...</td>\n",
       "      <td>HC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>C:\\Projects\\TFM\\dataset\\AD_MCI_HC_WINDOWED\\AD\\...</td>\n",
       "      <td>AD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8129</th>\n",
       "      <td>C:\\Projects\\TFM\\dataset\\AD_MCI_HC_WINDOWED\\HC\\...</td>\n",
       "      <td>HC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7024</th>\n",
       "      <td>C:\\Projects\\TFM\\dataset\\AD_MCI_HC_WINDOWED\\HC\\...</td>\n",
       "      <td>HC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>C:\\Projects\\TFM\\dataset\\AD_MCI_HC_WINDOWED\\AD\\...</td>\n",
       "      <td>AD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8374</th>\n",
       "      <td>C:\\Projects\\TFM\\dataset\\AD_MCI_HC_WINDOWED\\HC\\...</td>\n",
       "      <td>HC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>C:\\Projects\\TFM\\dataset\\AD_MCI_HC_WINDOWED\\AD\\...</td>\n",
       "      <td>AD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>C:\\Projects\\TFM\\dataset\\AD_MCI_HC_WINDOWED\\AD\\...</td>\n",
       "      <td>AD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4005 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   path label\n",
       "506   C:\\Projects\\TFM\\dataset\\AD_MCI_HC_WINDOWED\\AD\\...    AD\n",
       "2407  C:\\Projects\\TFM\\dataset\\AD_MCI_HC_WINDOWED\\AD\\...    AD\n",
       "8716  C:\\Projects\\TFM\\dataset\\AD_MCI_HC_WINDOWED\\HC\\...    HC\n",
       "1979  C:\\Projects\\TFM\\dataset\\AD_MCI_HC_WINDOWED\\AD\\...    AD\n",
       "8129  C:\\Projects\\TFM\\dataset\\AD_MCI_HC_WINDOWED\\HC\\...    HC\n",
       "...                                                 ...   ...\n",
       "7024  C:\\Projects\\TFM\\dataset\\AD_MCI_HC_WINDOWED\\HC\\...    HC\n",
       "835   C:\\Projects\\TFM\\dataset\\AD_MCI_HC_WINDOWED\\AD\\...    AD\n",
       "8374  C:\\Projects\\TFM\\dataset\\AD_MCI_HC_WINDOWED\\HC\\...    HC\n",
       "231   C:\\Projects\\TFM\\dataset\\AD_MCI_HC_WINDOWED\\AD\\...    AD\n",
       "263   C:\\Projects\\TFM\\dataset\\AD_MCI_HC_WINDOWED\\AD\\...    AD\n",
       "\n",
       "[4005 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "indices = pd.read_csv(INDEX_PATH, index_col=\"Unnamed: 0\")\n",
    "\n",
    "indices = indices.drop(indices[indices.label == \"MCI\"].index)\n",
    "\n",
    "indices_hc = indices[indices.label == 'HC'].sample(frac=0.4)\n",
    "indices_ad = indices[indices.label == 'AD']\n",
    "indices = pd.concat([indices_hc, indices_ad])\n",
    "\n",
    "train_data, test_data = train_test_split(indices, shuffle=True)\n",
    "\n",
    "builder = RawAndPearson(normalize_nodes=True, normalize_edges=True)\n",
    "#builder = MomentsAndPearson()\n",
    "\n",
    "train_dataset = BaseDataset(train_data, builder)\n",
    "test_dataset = BaseDataset(test_data, builder)\n",
    "\n",
    "#len(indices[indices.label == \"HC\"])\n",
    "# MCI 4430 -> 2\n",
    "# AD 2756 -> 0\n",
    "# HC 6641 -> 1\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_class_weights():\n",
    "    class_counts = counts\n",
    "    numDataPoints = class_counts.sum()\n",
    "\n",
    "\n",
    "    target = torch.cat((torch.zeros(class_counts[0], dtype=torch.long),\n",
    "                        torch.ones(class_counts[1], dtype=torch.long),\n",
    "                        torch.ones(class_counts[2], dtype=torch.long) * 2))\n",
    "\n",
    "    print('target train 0/1/2: {}/{}/{}'.format(\n",
    "        (target == 0).sum(), (target == 1).sum(), (target == 2).sum()))\n",
    "\n",
    "    # Compute samples weight (each sample should get its own weight)\n",
    "    class_sample_count = torch.tensor(\n",
    "        [(target == t).sum() for t in torch.unique(target, sorted=True)])\n",
    "    weight = 1. / class_sample_count.float()\n",
    "    samples_weight = torch.tensor([weight[t] for t in target])\n",
    "\n",
    "    # Create sampler, dataset, loader\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "\n",
    "    #train_dataset = torch.utils.data.TensorDataset(data, target)\n",
    "    #train_dataset = triaxial_dataset(data, target)\n",
    "\n",
    "    # Iterate DataLoader and check class balance for each batch\n",
    "    for i, (data) in enumerate(train_dataloader):\n",
    "        print(\"batch index {}, 0/1/2: {}/{}/{}\".format(\n",
    "            i, (data.label == 0).sum(), (data.label == 1).sum(), (data.label == 2).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "_BATCH_SIZE = 256\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=_BATCH_SIZE, shuffle=True)#sampler=weighted_sampler)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=_BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "extract_features() got an unexpected keyword argument 'normalize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lokix\\OneDrive\\Documents\\univsersidad\\MASTER\\1B\\TFM\\src_v3\\main.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000009?line=3'>4</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(data[\u001b[39m0\u001b[39m]))[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000009?line=4'>5</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000009?line=6'>7</a>\u001b[0m check_data()\n",
      "\u001b[1;32mc:\\Users\\lokix\\OneDrive\\Documents\\univsersidad\\MASTER\\1B\\TFM\\src_v3\\main.ipynb Cell 8'\u001b[0m in \u001b[0;36mcheck_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000009?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_data\u001b[39m():\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000009?line=1'>2</a>\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m train_dataloader:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000009?line=2'>3</a>\u001b[0m         \u001b[39mprint\u001b[39m(data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39medge_attr)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000009?line=3'>4</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(data[\u001b[39m0\u001b[39m]))[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\lokix\\Envs\\tfm\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=527'>528</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=528'>529</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=529'>530</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=530'>531</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=531'>532</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=532'>533</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=533'>534</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\lokix\\Envs\\tfm\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=567'>568</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=568'>569</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=569'>570</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=570'>571</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=571'>572</a>\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32mc:\\Users\\lokix\\Envs\\tfm\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\lokix\\Envs\\tfm\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32mc:\\Users\\lokix\\OneDrive\\Documents\\univsersidad\\MASTER\\1B\\TFM\\src_v3\\main.ipynb Cell 4'\u001b[0m in \u001b[0;36mBaseDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000003?line=14'>15</a>\u001b[0m raw_data \u001b[39m=\u001b[39m read_record(current_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000003?line=15'>16</a>\u001b[0m label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39miloc[idx][\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000003?line=16'>17</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuilder\u001b[39m.\u001b[39;49mbuild(raw_data, label)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000003?line=18'>19</a>\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\lokix\\OneDrive\\Documents\\univsersidad\\MASTER\\1B\\TFM\\src_v3\\entities\\graphs\\graph_builder.py:59\u001b[0m, in \u001b[0;36mRawAndPearson.build\u001b[1;34m(self, data, label)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/entities/graphs/graph_builder.py?line=57'>58</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild\u001b[39m(\u001b[39mself\u001b[39m, data, label):\n\u001b[1;32m---> <a href='file:///c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/entities/graphs/graph_builder.py?line=58'>59</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mbuild(data, label)\n",
      "File \u001b[1;32mc:\\Users\\lokix\\OneDrive\\Documents\\univsersidad\\MASTER\\1B\\TFM\\src_v3\\entities\\graphs\\graph_builder.py:22\u001b[0m, in \u001b[0;36mBaseGraphBuilder.build\u001b[1;34m(self, data, label)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/entities/graphs/graph_builder.py?line=19'>20</a>\u001b[0m \u001b[39m@abstractmethod\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/entities/graphs/graph_builder.py?line=20'>21</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild\u001b[39m(\u001b[39mself\u001b[39m, data, label):\n\u001b[1;32m---> <a href='file:///c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/entities/graphs/graph_builder.py?line=21'>22</a>\u001b[0m     node_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_feature_extractor\u001b[39m.\u001b[39;49mextract_features(data, normalize\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnormalize_nodes)\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/entities/graphs/graph_builder.py?line=22'>23</a>\u001b[0m     edge_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medge_feature_extractor\u001b[39m.\u001b[39mextract_features(data, normalize\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnormalize_edges)\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/entities/graphs/graph_builder.py?line=23'>24</a>\u001b[0m     format_label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_label(label)\n",
      "\u001b[1;31mTypeError\u001b[0m: extract_features() got an unexpected keyword argument 'normalize'"
     ]
    }
   ],
   "source": [
    "def check_data():\n",
    "    for data in train_dataloader:\n",
    "        print(data[0].edge_attr)\n",
    "        print(next(iter(data[0]))[1].shape)\n",
    "        break\n",
    "\n",
    "check_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from entities.models.factory import ModelFactory\n",
    "from entities.models.modelsTypes import Model\n",
    "\n",
    "model_factory = ModelFactory()\n",
    "model = model_factory.create(Model.EEGGRAPHCONVNET)\n",
    "model = model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EEGGraphConvNet(\n",
       "  (conv1): GCNConv(6, 16)\n",
       "  (conv2): GCNConv(16, 32)\n",
       "  (conv3): GCNConv(32, 64)\n",
       "  (conv4): GCNConv(64, 50)\n",
       "  (batch_norm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=50, out_features=30, bias=True)\n",
       "  (fc2): Linear(in_features=30, out_features=20, bias=True)\n",
       "  (fc3): Linear(in_features=20, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()#weight=torch.tensor([3, 1], dtype=torch.float64)) \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0: 0.694 loss\n",
      "Train Bal.ACC: 0.5688278343846029, test Bal.ACC: 0.5654058003597122\n",
      "Epoch: 000, Train Acc: 0.5620, Test Acc: 0.5558\n",
      "Training epoch 1: 0.696 loss\n",
      "Train Bal.ACC: 0.5718030621596852, test Bal.ACC: 0.5693738758992806\n",
      "Epoch: 001, Train Acc: 0.5648, Test Acc: 0.5596\n",
      "Training epoch 2: 0.702 loss\n",
      "Train Bal.ACC: 0.5009704027171276, test Bal.ACC: 0.5035971223021583\n",
      "Epoch: 002, Train Acc: 0.4864, Test Acc: 0.4831\n",
      "Training epoch 3: 0.695 loss\n",
      "Train Bal.ACC: 0.5033683307276223, test Bal.ACC: 0.5044964028776978\n",
      "Epoch: 003, Train Acc: 0.4901, Test Acc: 0.4861\n",
      "Training epoch 4: 0.693 loss\n",
      "Train Bal.ACC: 0.5759407515229932, test Bal.ACC: 0.5713916366906475\n",
      "Epoch: 004, Train Acc: 0.5678, Test Acc: 0.5603\n",
      "Training epoch 5: 0.694 loss\n",
      "Train Bal.ACC: 0.5731676909806458, test Bal.ACC: 0.5698684802158274\n",
      "Epoch: 005, Train Acc: 0.5658, Test Acc: 0.5596\n",
      "Training epoch 6: 0.691 loss\n",
      "Train Bal.ACC: 0.5716244811041027, test Bal.ACC: 0.5705260791366906\n",
      "Epoch: 006, Train Acc: 0.5643, Test Acc: 0.5603\n",
      "Training epoch 7: 0.691 loss\n",
      "Train Bal.ACC: 0.5712325013028555, test Bal.ACC: 0.5678956834532374\n",
      "Epoch: 007, Train Acc: 0.5635, Test Acc: 0.5573\n",
      "Training epoch 8: 0.689 loss\n",
      "Train Bal.ACC: 0.5703440886301149, test Bal.ACC: 0.5699303057553957\n",
      "Epoch: 008, Train Acc: 0.5628, Test Acc: 0.5596\n",
      "Training epoch 9: 0.691 loss\n",
      "Train Bal.ACC: 0.571013486800726, test Bal.ACC: 0.569806654676259\n",
      "Epoch: 009, Train Acc: 0.5635, Test Acc: 0.5596\n",
      "Training epoch 10: 0.692 loss\n",
      "Train Bal.ACC: 0.5712763042032813, test Bal.ACC: 0.5679575089928057\n",
      "Epoch: 010, Train Acc: 0.5635, Test Acc: 0.5573\n",
      "Training epoch 11: 0.691 loss\n",
      "Train Bal.ACC: 0.5716738997609934, test Bal.ACC: 0.5700539568345324\n",
      "Epoch: 011, Train Acc: 0.5640, Test Acc: 0.5596\n",
      "Training epoch 12: 0.690 loss\n",
      "Train Bal.ACC: 0.571130294535195, test Bal.ACC: 0.5699303057553957\n",
      "Epoch: 012, Train Acc: 0.5635, Test Acc: 0.5596\n",
      "Training epoch 13: 0.689 loss\n",
      "Train Bal.ACC: 0.5697712814706992, test Bal.ACC: 0.5698684802158274\n",
      "Epoch: 013, Train Acc: 0.5623, Test Acc: 0.5596\n",
      "Training epoch 14: 0.689 loss\n",
      "Train Bal.ACC: 0.5696544737362301, test Bal.ACC: 0.5689635791366907\n",
      "Epoch: 014, Train Acc: 0.5623, Test Acc: 0.5588\n",
      "Training epoch 15: 0.687 loss\n",
      "Train Bal.ACC: 0.57033847287365, test Bal.ACC: 0.568839928057554\n",
      "Epoch: 015, Train Acc: 0.5630, Test Acc: 0.5588\n",
      "Training epoch 16: 0.689 loss\n",
      "Train Bal.ACC: 0.5673284274084857, test Bal.ACC: 0.5661252248201439\n",
      "Epoch: 016, Train Acc: 0.5605, Test Acc: 0.5566\n",
      "Training epoch 17: 0.694 loss\n",
      "Train Bal.ACC: 0.5681730371808004, test Bal.ACC: 0.5669683003597122\n",
      "Epoch: 017, Train Acc: 0.5613, Test Acc: 0.5573\n",
      "Training epoch 18: 0.687 loss\n",
      "Train Bal.ACC: 0.5684156378600823, test Bal.ACC: 0.5669064748201439\n",
      "Epoch: 018, Train Acc: 0.5615, Test Acc: 0.5573\n",
      "Training epoch 19: 0.686 loss\n",
      "Train Bal.ACC: 0.5693242672560965, test Bal.ACC: 0.568839928057554\n",
      "Epoch: 019, Train Acc: 0.5620, Test Acc: 0.5588\n",
      "Training epoch 20: 0.688 loss\n",
      "Train Bal.ACC: 0.569183873344475, test Bal.ACC: 0.5683059802158273\n",
      "Epoch: 020, Train Acc: 0.5618, Test Acc: 0.5581\n",
      "Training epoch 21: 0.687 loss\n",
      "Train Bal.ACC: 0.5684414703398206, test Bal.ACC: 0.569806654676259\n",
      "Epoch: 021, Train Acc: 0.5610, Test Acc: 0.5596\n",
      "Training epoch 22: 0.685 loss\n",
      "Train Bal.ACC: 0.5675676586338886, test Bal.ACC: 0.5689017535971224\n",
      "Epoch: 022, Train Acc: 0.5603, Test Acc: 0.5588\n",
      "Training epoch 23: 0.686 loss\n",
      "Train Bal.ACC: 0.5690086617427714, test Bal.ACC: 0.568839928057554\n",
      "Epoch: 023, Train Acc: 0.5618, Test Acc: 0.5588\n",
      "Training epoch 24: 0.684 loss\n",
      "Train Bal.ACC: 0.5651798389850307, test Bal.ACC: 0.5664961780575539\n",
      "Epoch: 024, Train Acc: 0.5581, Test Acc: 0.5566\n",
      "Training epoch 25: 0.691 loss\n",
      "Train Bal.ACC: 0.5651102036048664, test Bal.ACC: 0.5583127248201439\n",
      "Epoch: 025, Train Acc: 0.5586, Test Acc: 0.5491\n",
      "Training epoch 26: 0.685 loss\n",
      "Train Bal.ACC: 0.5662232465362014, test Bal.ACC: 0.5665580035971223\n",
      "Epoch: 026, Train Acc: 0.5591, Test Acc: 0.5566\n",
      "Training epoch 27: 0.685 loss\n",
      "Train Bal.ACC: 0.5672172354304814, test Bal.ACC: 0.5640287769784174\n",
      "Epoch: 027, Train Acc: 0.5603, Test Acc: 0.5543\n",
      "Training epoch 28: 0.683 loss\n",
      "Train Bal.ACC: 0.5662760346469711, test Bal.ACC: 0.5633093525179856\n",
      "Epoch: 028, Train Acc: 0.5593, Test Acc: 0.5536\n",
      "Training epoch 29: 0.685 loss\n",
      "Train Bal.ACC: 0.5660334339676891, test Bal.ACC: 0.5633093525179856\n",
      "Epoch: 029, Train Acc: 0.5591, Test Acc: 0.5536\n",
      "Training epoch 30: 0.683 loss\n",
      "Train Bal.ACC: 0.5660334339676891, test Bal.ACC: 0.5633093525179856\n",
      "Epoch: 030, Train Acc: 0.5591, Test Acc: 0.5536\n",
      "Training epoch 31: 0.683 loss\n",
      "Train Bal.ACC: 0.5660772368681151, test Bal.ACC: 0.564152428057554\n",
      "Epoch: 031, Train Acc: 0.5591, Test Acc: 0.5543\n",
      "Training epoch 32: 0.684 loss\n",
      "Train Bal.ACC: 0.5660626359013065, test Bal.ACC: 0.5625899280575539\n",
      "Epoch: 032, Train Acc: 0.5591, Test Acc: 0.5528\n",
      "Training epoch 33: 0.684 loss\n",
      "Train Bal.ACC: 0.5660772368681151, test Bal.ACC: 0.564152428057554\n",
      "Epoch: 033, Train Acc: 0.5591, Test Acc: 0.5543\n",
      "Training epoch 34: 0.683 loss\n",
      "Train Bal.ACC: 0.5657908332884073, test Bal.ACC: 0.5625899280575539\n",
      "Epoch: 034, Train Acc: 0.5588, Test Acc: 0.5528\n",
      "Training epoch 35: 0.683 loss\n",
      "Train Bal.ACC: 0.5659076410228763, test Bal.ACC: 0.5649955035971224\n",
      "Epoch: 035, Train Acc: 0.5588, Test Acc: 0.5551\n",
      "Training epoch 36: 0.691 loss\n",
      "Train Bal.ACC: 0.566121039768541, test Bal.ACC: 0.5634330035971222\n",
      "Epoch: 036, Train Acc: 0.5591, Test Acc: 0.5536\n",
      "Training epoch 37: 0.683 loss\n",
      "Train Bal.ACC: 0.5662760346469711, test Bal.ACC: 0.5625899280575539\n",
      "Epoch: 037, Train Acc: 0.5593, Test Acc: 0.5528\n",
      "Training epoch 38: 0.682 loss\n",
      "Train Bal.ACC: 0.5662760346469711, test Bal.ACC: 0.5633093525179856\n",
      "Epoch: 038, Train Acc: 0.5593, Test Acc: 0.5536\n",
      "Training epoch 39: 0.683 loss\n",
      "Train Bal.ACC: 0.565960429133646, test Bal.ACC: 0.5632475269784173\n",
      "Epoch: 039, Train Acc: 0.5591, Test Acc: 0.5536\n",
      "Training epoch 40: 0.684 loss\n",
      "Train Bal.ACC: 0.5662760346469711, test Bal.ACC: 0.5633093525179856\n",
      "Epoch: 040, Train Acc: 0.5593, Test Acc: 0.5536\n",
      "Training epoch 41: 0.682 loss\n",
      "Train Bal.ACC: 0.565960429133646, test Bal.ACC: 0.5640287769784174\n",
      "Epoch: 041, Train Acc: 0.5591, Test Acc: 0.5543\n",
      "Training epoch 42: 0.682 loss\n",
      "Train Bal.ACC: 0.56576163135479, test Bal.ACC: 0.5633093525179856\n",
      "Epoch: 042, Train Acc: 0.5588, Test Acc: 0.5536\n",
      "Training epoch 43: 0.682 loss\n",
      "Train Bal.ACC: 0.5662468327133539, test Bal.ACC: 0.5633093525179856\n",
      "Epoch: 043, Train Acc: 0.5593, Test Acc: 0.5536\n",
      "Training epoch 44: 0.682 loss\n",
      "Train Bal.ACC: 0.5666882311714917, test Bal.ACC: 0.5631857014388489\n",
      "Epoch: 044, Train Acc: 0.5598, Test Acc: 0.5536\n",
      "Training epoch 45: 0.684 loss\n",
      "Train Bal.ACC: 0.56576163135479, test Bal.ACC: 0.5633093525179856\n",
      "Epoch: 045, Train Acc: 0.5588, Test Acc: 0.5536\n",
      "Training epoch 46: 0.683 loss\n",
      "Train Bal.ACC: 0.5660772368681151, test Bal.ACC: 0.564152428057554\n",
      "Epoch: 046, Train Acc: 0.5591, Test Acc: 0.5543\n",
      "Training epoch 47: 0.695 loss\n",
      "Train Bal.ACC: 0.5654898287418909, test Bal.ACC: 0.5640287769784174\n",
      "Epoch: 047, Train Acc: 0.5586, Test Acc: 0.5543\n",
      "Training epoch 48: 0.682 loss\n",
      "Train Bal.ACC: 0.565601020719895, test Bal.ACC: 0.5631238758992806\n",
      "Epoch: 048, Train Acc: 0.5588, Test Acc: 0.5536\n",
      "Training epoch 49: 0.682 loss\n",
      "Train Bal.ACC: 0.5655190306755081, test Bal.ACC: 0.561808678057554\n",
      "Epoch: 049, Train Acc: 0.5586, Test Acc: 0.5521\n",
      "Training epoch 50: 0.682 loss\n",
      "Train Bal.ACC: 0.5658728233327942, test Bal.ACC: 0.5624044514388489\n",
      "Epoch: 050, Train Acc: 0.5591, Test Acc: 0.5528\n",
      "Training epoch 51: 0.683 loss\n",
      "Train Bal.ACC: 0.56576163135479, test Bal.ACC: 0.5625281025179856\n",
      "Epoch: 051, Train Acc: 0.5588, Test Acc: 0.5528\n",
      "Training epoch 52: 0.681 loss\n",
      "Train Bal.ACC: 0.5655044297086995, test Bal.ACC: 0.5625281025179856\n",
      "Epoch: 052, Train Acc: 0.5586, Test Acc: 0.5528\n",
      "Training epoch 53: 0.682 loss\n",
      "Train Bal.ACC: 0.5657032274875555, test Bal.ACC: 0.5632475269784173\n",
      "Epoch: 053, Train Acc: 0.5588, Test Acc: 0.5536\n",
      "Training epoch 54: 0.682 loss\n",
      "Train Bal.ACC: 0.56576163135479, test Bal.ACC: 0.5625281025179856\n",
      "Epoch: 054, Train Acc: 0.5588, Test Acc: 0.5528\n",
      "Training epoch 55: 0.682 loss\n",
      "Train Bal.ACC: 0.5657324294211727, test Bal.ACC: 0.5625281025179856\n",
      "Epoch: 055, Train Acc: 0.5588, Test Acc: 0.5528\n",
      "Training epoch 56: 0.682 loss\n",
      "Train Bal.ACC: 0.56576163135479, test Bal.ACC: 0.5633093525179856\n",
      "Epoch: 056, Train Acc: 0.5588, Test Acc: 0.5536\n",
      "Training epoch 57: 0.681 loss\n",
      "Train Bal.ACC: 0.565601020719895, test Bal.ACC: 0.5631238758992806\n",
      "Epoch: 057, Train Acc: 0.5588, Test Acc: 0.5536\n",
      "Training epoch 58: 0.682 loss\n",
      "Train Bal.ACC: 0.565601020719895, test Bal.ACC: 0.5631238758992806\n",
      "Epoch: 058, Train Acc: 0.5588, Test Acc: 0.5536\n",
      "Training epoch 59: 0.682 loss\n",
      "Train Bal.ACC: 0.565601020719895, test Bal.ACC: 0.5631238758992806\n",
      "Epoch: 059, Train Acc: 0.5588, Test Acc: 0.5536\n",
      "Training epoch 60: 0.683 loss\n",
      "Train Bal.ACC: 0.5658290204323684, test Bal.ACC: 0.5631238758992806\n",
      "Epoch: 060, Train Acc: 0.5591, Test Acc: 0.5536\n",
      "Training epoch 61: 0.681 loss\n",
      "Train Bal.ACC: 0.5658582223659856, test Bal.ACC: 0.5631238758992806\n",
      "Epoch: 061, Train Acc: 0.5591, Test Acc: 0.5536\n",
      "Training epoch 62: 0.685 loss\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lokix\\OneDrive\\Documents\\univsersidad\\MASTER\\1B\\TFM\\src_v3\\main.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 74>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000013?line=73'>74</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(_NUM_EPOCHS):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000013?line=74'>75</a>\u001b[0m     train()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000013?line=76'>77</a>\u001b[0m     train_acc, y_true_train, y_probs_train, y_pred_train \u001b[39m=\u001b[39m test(train_dataloader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000013?line=77'>78</a>\u001b[0m     test_acc, y_true_test, y_probs_test, y_pred_test \u001b[39m=\u001b[39m test(test_dataloader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000013?line=78'>79</a>\u001b[0m     train_accs\u001b[39m.\u001b[39mappend(train_acc)\n",
      "\u001b[1;32mc:\\Users\\lokix\\OneDrive\\Documents\\univsersidad\\MASTER\\1B\\TFM\\src_v3\\main.ipynb Cell 14'\u001b[0m in \u001b[0;36mtest\u001b[1;34m(loader)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000013?line=51'>52</a>\u001b[0m y_true_train, y_pred_train \u001b[39m=\u001b[39m [], []\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000013?line=52'>53</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000013?line=53'>54</a>\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m loader:  \u001b[39m# Iterate in batches over the training/test dataset.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000013?line=54'>55</a>\u001b[0m         out \u001b[39m=\u001b[39m model(data\u001b[39m.\u001b[39mx, data\u001b[39m.\u001b[39medge_index, data\u001b[39m.\u001b[39medge_attr, data\u001b[39m.\u001b[39mbatch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000013?line=55'>56</a>\u001b[0m         y_batch \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mlabel\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39m_DEVICE, non_blocking\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\lokix\\Envs\\tfm\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=527'>528</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=528'>529</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=529'>530</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=530'>531</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=531'>532</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=532'>533</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=533'>534</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\lokix\\Envs\\tfm\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=567'>568</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=568'>569</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=569'>570</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=570'>571</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=571'>572</a>\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32mc:\\Users\\lokix\\Envs\\tfm\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\lokix\\Envs\\tfm\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32mc:\\Users\\lokix\\OneDrive\\Documents\\univsersidad\\MASTER\\1B\\TFM\\src_v3\\main.ipynb Cell 4'\u001b[0m in \u001b[0;36mBaseDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000003?line=14'>15</a>\u001b[0m raw_data \u001b[39m=\u001b[39m read_record(current_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000003?line=15'>16</a>\u001b[0m label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39miloc[idx][\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000003?line=16'>17</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuilder\u001b[39m.\u001b[39;49mbuild(raw_data, label)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000003?line=18'>19</a>\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\lokix\\OneDrive\\Documents\\univsersidad\\MASTER\\1B\\TFM\\src_v3\\entities\\graphs\\graph_builder.py:66\u001b[0m, in \u001b[0;36mMomentsAndPearson.build\u001b[1;34m(self, data, label)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/entities/graphs/graph_builder.py?line=64'>65</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild\u001b[39m(\u001b[39mself\u001b[39m, data, label):\n\u001b[1;32m---> <a href='file:///c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/entities/graphs/graph_builder.py?line=65'>66</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mbuild(data, label)\n",
      "File \u001b[1;32mc:\\Users\\lokix\\OneDrive\\Documents\\univsersidad\\MASTER\\1B\\TFM\\src_v3\\entities\\graphs\\graph_builder.py:20\u001b[0m, in \u001b[0;36mBaseGraphBuilder.build\u001b[1;34m(self, data, label)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/entities/graphs/graph_builder.py?line=17'>18</a>\u001b[0m \u001b[39m@abstractmethod\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/entities/graphs/graph_builder.py?line=18'>19</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild\u001b[39m(\u001b[39mself\u001b[39m, data, label):\n\u001b[1;32m---> <a href='file:///c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/entities/graphs/graph_builder.py?line=19'>20</a>\u001b[0m     node_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_feature_extractor\u001b[39m.\u001b[39;49mextract_features(data)\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/entities/graphs/graph_builder.py?line=20'>21</a>\u001b[0m     edge_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medge_feature_extractor\u001b[39m.\u001b[39mextract_features(data)\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/entities/graphs/graph_builder.py?line=21'>22</a>\u001b[0m     format_label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_label(label)\n",
      "File \u001b[1;32mc:\\Users\\lokix\\OneDrive\\Documents\\univsersidad\\MASTER\\1B\\TFM\\src_v3\\entities\\graphs\\node_extractors.py:48\u001b[0m, in \u001b[0;36mStadisticalMomentsExtractor.extract_features\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/entities/graphs/node_extractors.py?line=45'>46</a>\u001b[0m std \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mstd(data, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/entities/graphs/node_extractors.py?line=46'>47</a>\u001b[0m variance \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvar(data, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='file:///c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/entities/graphs/node_extractors.py?line=47'>48</a>\u001b[0m entropy \u001b[39m=\u001b[39m stats\u001b[39m.\u001b[39;49mdifferential_entropy(data, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/entities/graphs/node_extractors.py?line=48'>49</a>\u001b[0m skewness \u001b[39m=\u001b[39m stats\u001b[39m.\u001b[39mskew(data, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/entities/graphs/node_extractors.py?line=49'>50</a>\u001b[0m kurtosis \u001b[39m=\u001b[39m stats\u001b[39m.\u001b[39mkurtosis(data, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lokix\\Envs\\tfm\\lib\\site-packages\\scipy\\stats\\_entropy.py:250\u001b[0m, in \u001b[0;36mdifferential_entropy\u001b[1;34m(values, window_length, base, axis, method)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/scipy/stats/_entropy.py?line=246'>247</a>\u001b[0m \u001b[39mif\u001b[39;00m base \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m base \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/scipy/stats/_entropy.py?line=247'>248</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`base` must be a positive number or `None`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/scipy/stats/_entropy.py?line=249'>250</a>\u001b[0m sorted_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49msort(values, axis\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/scipy/stats/_entropy.py?line=251'>252</a>\u001b[0m methods \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mvasicek\u001b[39m\u001b[39m\"\u001b[39m: _vasicek_entropy,\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/scipy/stats/_entropy.py?line=252'>253</a>\u001b[0m            \u001b[39m\"\u001b[39m\u001b[39mvan es\u001b[39m\u001b[39m\"\u001b[39m: _van_es_entropy,\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/scipy/stats/_entropy.py?line=253'>254</a>\u001b[0m            \u001b[39m\"\u001b[39m\u001b[39mcorrea\u001b[39m\u001b[39m\"\u001b[39m: _correa_entropy,\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/scipy/stats/_entropy.py?line=254'>255</a>\u001b[0m            \u001b[39m\"\u001b[39m\u001b[39mebrahimi\u001b[39m\u001b[39m\"\u001b[39m: _ebrahimi_entropy,\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/scipy/stats/_entropy.py?line=255'>256</a>\u001b[0m            \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m: _vasicek_entropy}\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/scipy/stats/_entropy.py?line=256'>257</a>\u001b[0m method \u001b[39m=\u001b[39m method\u001b[39m.\u001b[39mlower()\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msort\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\lokix\\Envs\\tfm\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1004\u001b[0m, in \u001b[0;36msort\u001b[1;34m(a, axis, kind, order)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/numpy/core/fromnumeric.py?line=1001'>1002</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/numpy/core/fromnumeric.py?line=1002'>1003</a>\u001b[0m     a \u001b[39m=\u001b[39m asanyarray(a)\u001b[39m.\u001b[39mcopy(order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mK\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/numpy/core/fromnumeric.py?line=1003'>1004</a>\u001b[0m a\u001b[39m.\u001b[39;49msort(axis\u001b[39m=\u001b[39;49maxis, kind\u001b[39m=\u001b[39;49mkind, order\u001b[39m=\u001b[39;49morder)\n\u001b[0;32m   <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/numpy/core/fromnumeric.py?line=1004'>1005</a>\u001b[0m \u001b[39mreturn\u001b[39;00m a\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score\n",
    "from numpy import mean\n",
    "\n",
    "auroc_train_history = []\n",
    "auroc_test_history = []\n",
    "balACC_train_history = []\n",
    "\n",
    "balACC_test_history = []\n",
    "loss_train_history = []\n",
    "loss_test_history = []\n",
    "\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "_NUM_EPOCHS = 1000\n",
    "_DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    batch_loss = []\n",
    "    for i, data in enumerate(train_dataloader):  # Iterate in batches over the training dataset.\n",
    "\n",
    "        data.batch = data.batch.view(data.batch.shape[0], -1)\n",
    "        \n",
    "        out = model(data.x, data.edge_index, data.edge_attr,\n",
    "                    data.batch)  # Perform a single forward pass.\n",
    "        \n",
    "        \n",
    "\n",
    "        loss = criterion(out, data.label)  # Compute the loss.\n",
    "        #print(loss.item())\n",
    "        batch_loss.append(loss.item())\n",
    "        #print(data.label)\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i%100 == 99:\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n",
    "    print(f\"Training epoch {epoch}: {mean(batch_loss):.3f} loss\")\n",
    "    scheduler.step()\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    y_probs_train = torch.empty(0, 2).to(_DEVICE)\n",
    "    y_true_train, y_pred_train = [], []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "            out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
    "            y_batch = data.label.to(device=_DEVICE, non_blocking=True)\n",
    "            \n",
    "            pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "            \n",
    "            #print(pred)\n",
    "            \n",
    "            correct += int((pred == data.label).sum())  # Check against ground-truth labels.\n",
    "            y_pred_train += pred.cpu().numpy().tolist()\n",
    "            \n",
    "            y_probs_train = torch.cat((y_probs_train, out.data), 0)\n",
    "            y_true_train += y_batch.cpu().numpy().tolist()\n",
    "            \n",
    "    y_probs_train = torch.nn.functional.softmax(y_probs_train, dim=1).cpu().numpy()\n",
    "    y_true_train = np.array(y_true_train)\n",
    "\n",
    "    return correct / len(loader.dataset), y_true_train, y_probs_train, y_pred_train  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "for epoch in range(_NUM_EPOCHS):\n",
    "    train()\n",
    "    \n",
    "    train_acc, y_true_train, y_probs_train, y_pred_train = test(train_dataloader)\n",
    "    test_acc, y_true_test, y_probs_test, y_pred_test = test(test_dataloader)\n",
    "    train_accs.append(train_acc)\n",
    "    test_accs.append(test_acc)\n",
    "\n",
    "    balACC_train_history.append(balanced_accuracy_score(y_true_train, y_pred_train))\n",
    "    balACC_test_history.append(balanced_accuracy_score(y_true_test, y_pred_test))\n",
    "\n",
    "    print(\"Train Bal.ACC: {}, test Bal.ACC: {}\".format(balACC_train_history[-1], balACC_test_history[-1]))\n",
    "    \n",
    "    \n",
    "    print(\n",
    "        f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1dc6b797490>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_true_train, y_pred_train)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=[\"AD\", \"HC\"])\n",
    "\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here starts the version using DGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "from dgl.data import DGLDataset\n",
    "    \n",
    "# Source code from the paper, no changes made\n",
    "class EEGGraphDataset(DGLDataset):\n",
    "\tdef __init__(self, indices, builder, num_nodes):\n",
    "\t\t# CAUTION - x and labels are memory-mapped, used as if they are in RAM.\n",
    "\t\tself.num_nodes = num_nodes\n",
    "\t\tself.builder = builder\n",
    "\t\tself.indices = indices\n",
    "\n",
    "\t\n",
    "    # returns size of dataset = number of indices\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.indices)\n",
    "\n",
    "\t# retrieve one sample from the dataset after applying all transforms\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tsrc = [[0 for i in range(self.num_nodes)] for j in range(self.num_nodes)]\n",
    "\t\tfor i in range(len(src)):\n",
    "\t\t\tfor j in range(len(src[i])):\n",
    "\t\t\t\tsrc[i][j] = i\n",
    "\t\tsrc = np.array(src).flatten()\n",
    "\n",
    "\t\tdet = [[i for i in range(self.num_nodes)] for j in range(self.num_nodes)]\n",
    "\t\tdet = np.array(det).flatten()\n",
    "\n",
    "\t\tu, v = (torch.tensor(src), torch.tensor(det))\n",
    "\t\tprint(u)\n",
    "\t\t\n",
    "\t\tg = dgl.graph((u, v))\n",
    "\n",
    "\t\tcurrent_path = self.indices.iloc[idx][\"path\"]\n",
    "\t\traw_data = read_record(current_path)\n",
    "\t\tlabel = self.indices.iloc[idx][\"label\"]\n",
    "\t\tdata = self.builder.build(raw_data, label)\n",
    "\n",
    "\t\t# add node features and edge features\n",
    "\t\tg.ndata['x'] = data.x\n",
    "\t\tg.edata['edge_weights'] = data.edge_attr\n",
    "\t\tlabel = data.label\n",
    "\t\treturn g, torch.tensor(idx), torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "indices = pd.read_csv(INDEX_PATH, index_col=\"Unnamed: 0\")\n",
    "#indices = indices.drop(indices[indices.label == \"MCI\"].index)\n",
    "train_data, test_data = train_test_split(indices)\n",
    "\n",
    "builder = RawAndPearson()\n",
    "#builder = MomentsAndPearson()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4005\n",
      "[2756 6461 4430]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00036284, 0.00015477, 0.00022573])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "import numpy as np\n",
    "\n",
    "labels_unique, counts = np.unique(indices[\"label\"], return_counts=True)\n",
    "\n",
    "class_weights = np.array([1.0 / x for x in counts])\n",
    "# provide weights for samples in the training set only\n",
    "weighted_sampler = WeightedRandomSampler(\n",
    "    weights=class_weights,\n",
    "    num_samples=len(train_data), replacement=True\n",
    ")\n",
    "print(len(train_dataset))\n",
    "print(counts)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "_BATCH_SIZE = 64\n",
    "NUM_WORKERS = 0\n",
    "PIN_MEMORY = True\n",
    "_NUM_NODES = 19\n",
    "\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "\n",
    "train_dataset = EEGGraphDataset(train_data, builder, _NUM_NODES)\n",
    "\n",
    "test_dataset = EEGGraphDataset(test_data, builder, _NUM_NODES)\n",
    "\n",
    "train_batches = GraphDataLoader(dataset=train_dataset,\n",
    "                           batch_size=_BATCH_SIZE,\n",
    "                           shuffle=False,\n",
    "                           sampler=weighted_sampler,\n",
    "                           num_workers=NUM_WORKERS,\n",
    "                           pin_memory=PIN_MEMORY)\n",
    "\n",
    "test_batches = GraphDataLoader(dataset=test_dataset,\n",
    "                          batch_size=_BATCH_SIZE,\n",
    "                          shuffle=False,\n",
    "                          num_workers=NUM_WORKERS,\n",
    "                          pin_memory=PIN_MEMORY)\n",
    "\n",
    "\n",
    "train_metrics_loader = GraphDataLoader(\n",
    "        dataset=test_dataset, batch_size=_BATCH_SIZE,\n",
    "        shuffle=False, num_workers=NUM_WORKERS,\n",
    "        pin_memory=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from entities.models.factory import ModelFactory\n",
    "from entities.models.modelsTypes import Model\n",
    "\n",
    "model_factory = ModelFactory()\n",
    "model = model_factory.create(Model.EEGGRAPHCONVNET)\n",
    "model = model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[i * 10 for i in range(1, 26)], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
      "         6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
      "         7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
      "         8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
      "         9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11,\n",
      "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12,\n",
      "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13,\n",
      "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14,\n",
      "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15,\n",
      "        15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17,\n",
      "        17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
      "        18], dtype=torch.int32)\n"
     ]
    },
    {
     "ename": "DGLError",
     "evalue": "Expect number of features to match number of edges. Got 19 and 361 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDGLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lokix\\OneDrive\\Documents\\univsersidad\\MASTER\\1B\\TFM\\src_v3\\main.ipynb Cell 24'\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000023?line=19'>20</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000023?line=20'>21</a>\u001b[0m train_loss \u001b[39m=\u001b[39m []\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000023?line=22'>23</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_batches):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000023?line=23'>24</a>\u001b[0m     \u001b[39m# send batch to GPU\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000023?line=24'>25</a>\u001b[0m     g, dataset_idx, y \u001b[39m=\u001b[39m batch\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000023?line=25'>26</a>\u001b[0m     g_batch \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39m_DEVICE, non_blocking\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\lokix\\Envs\\tfm\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=527'>528</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=528'>529</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=529'>530</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=530'>531</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=531'>532</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=532'>533</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=533'>534</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\lokix\\Envs\\tfm\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=567'>568</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=568'>569</a>\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=569'>570</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=570'>571</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/dataloader.py?line=571'>572</a>\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32mc:\\Users\\lokix\\Envs\\tfm\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\lokix\\Envs\\tfm\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=46'>47</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=47'>48</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=48'>49</a>\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=49'>50</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/torch/utils/data/_utils/fetch.py?line=50'>51</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32mc:\\Users\\lokix\\OneDrive\\Documents\\univsersidad\\MASTER\\1B\\TFM\\src_v3\\main.ipynb Cell 18'\u001b[0m in \u001b[0;36mEEGGraphDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000017?line=37'>38</a>\u001b[0m \u001b[39m# add node features and edge features\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000017?line=38'>39</a>\u001b[0m g\u001b[39m.\u001b[39mndata[\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mx\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000017?line=39'>40</a>\u001b[0m g\u001b[39m.\u001b[39medata[\u001b[39m'\u001b[39m\u001b[39medge_weights\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39medge_attr\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000017?line=40'>41</a>\u001b[0m label \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mlabel\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lokix/OneDrive/Documents/univsersidad/MASTER/1B/TFM/src_v3/main.ipynb#ch0000017?line=41'>42</a>\u001b[0m \u001b[39mreturn\u001b[39;00m g, torch\u001b[39m.\u001b[39mtensor(idx), torch\u001b[39m.\u001b[39mtensor(label)\n",
      "File \u001b[1;32mc:\\Users\\lokix\\Envs\\tfm\\lib\\site-packages\\dgl\\view.py:198\u001b[0m, in \u001b[0;36mHeteroEdgeDataView.__setitem__\u001b[1;34m(self, key, val)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/dgl/view.py?line=193'>194</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/dgl/view.py?line=194'>195</a>\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(val, \u001b[39mdict\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \\\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/dgl/view.py?line=195'>196</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mThe HeteroEdgeDataView has only one edge type. \u001b[39m\u001b[39m'\u001b[39m \\\n\u001b[0;32m    <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/dgl/view.py?line=196'>197</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mplease pass a tensor directly\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/dgl/view.py?line=197'>198</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_graph\u001b[39m.\u001b[39;49m_set_e_repr(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_etid, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_edges, {key : val})\n",
      "File \u001b[1;32mc:\\Users\\lokix\\Envs\\tfm\\lib\\site-packages\\dgl\\heterograph.py:4220\u001b[0m, in \u001b[0;36mDGLHeteroGraph._set_e_repr\u001b[1;34m(self, etid, edges, data)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/dgl/heterograph.py?line=4217'>4218</a>\u001b[0m nfeats \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mshape(val)[\u001b[39m0\u001b[39m]\n\u001b[0;32m   <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/dgl/heterograph.py?line=4218'>4219</a>\u001b[0m \u001b[39mif\u001b[39;00m nfeats \u001b[39m!=\u001b[39m num_edges:\n\u001b[1;32m-> <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/dgl/heterograph.py?line=4219'>4220</a>\u001b[0m     \u001b[39mraise\u001b[39;00m DGLError(\u001b[39m'\u001b[39m\u001b[39mExpect number of features to match number of edges.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/dgl/heterograph.py?line=4220'>4221</a>\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m Got \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (nfeats, num_edges))\n\u001b[0;32m   <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/dgl/heterograph.py?line=4221'>4222</a>\u001b[0m \u001b[39mif\u001b[39;00m F\u001b[39m.\u001b[39mcontext(val) \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice:\n\u001b[0;32m   <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/dgl/heterograph.py?line=4222'>4223</a>\u001b[0m     \u001b[39mraise\u001b[39;00m DGLError(\u001b[39m'\u001b[39m\u001b[39mCannot assign edge feature \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m on device \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m to a graph on\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/dgl/heterograph.py?line=4223'>4224</a>\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m device \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. Call DGLGraph.to() to copy the graph to the\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/lokix/Envs/tfm/lib/site-packages/dgl/heterograph.py?line=4224'>4225</a>\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39m same device.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(key, F\u001b[39m.\u001b[39mcontext(val), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice))\n",
      "\u001b[1;31mDGLError\u001b[0m: Expect number of features to match number of edges. Got 19 and 361 instead."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score\n",
    "\n",
    "\n",
    "num_trainable_params = np.sum([np.prod(p.size()) if p.requires_grad else 0 for p in model.parameters()])\n",
    "\n",
    "auroc_train_history = []\n",
    "auroc_test_history = []\n",
    "balACC_train_history = []\n",
    "\n",
    "balACC_test_history = []\n",
    "loss_train_history = []\n",
    "loss_test_history = []\n",
    "_NUM_EPOCHS = 50\n",
    "_DEVICE = torch.device(\"cpu\")\n",
    "_EXPERIMENT_NAME = \"FIRST_TRIAL\"\n",
    "\n",
    "\n",
    "# training=========================================================================================================\n",
    "for epoch in range(_NUM_EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_batches):\n",
    "        # send batch to GPU\n",
    "        g, dataset_idx, y = batch\n",
    "        g_batch = g.to(device=_DEVICE, non_blocking=True)\n",
    "        y_batch = y.to(device=_DEVICE, non_blocking=True)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(g_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # update learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "# evaluate model after each epoch for train-metric data============================================================\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_probs_train = torch.empty(0, 2).to(_DEVICE)\n",
    "        y_true_train, y_pred_train = [], []\n",
    "\n",
    "        for i, batch in enumerate(train_metrics_loader):\n",
    "            g, dataset_idx, y = batch\n",
    "            g_batch = g.to(device=_DEVICE, non_blocking=True)\n",
    "            y_batch = y.to(device=_DEVICE, non_blocking=True)\n",
    "\n",
    "            # forward pass\n",
    "            outputs = model(g_batch)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            y_pred_train += predicted.cpu().numpy().tolist()\n",
    "            # concatenate along 0th dimension\n",
    "            y_probs_train = torch.cat((y_probs_train, outputs.data), 0)\n",
    "            y_true_train += y_batch.cpu().numpy().tolist()\n",
    "\n",
    "    # returning prob distribution over target classes, take softmax over the 1st dimension\n",
    "    y_probs_train = torch.nn.functional.softmax(y_probs_train, dim=1).cpu().numpy()\n",
    "    y_true_train = np.array(y_true_train)\n",
    "\n",
    "# evaluate model after each epoch for validation data ==============================================================\n",
    "    y_probs_test = torch.empty(0, 2).to(_DEVICE)\n",
    "    y_true_test, minibatch_loss, y_pred_test = [], [], []\n",
    "\n",
    "    for i, batch in enumerate(test_batches):\n",
    "        g, dataset_idx, y = batch\n",
    "        g_batch = g.to(device=_DEVICE, non_blocking=True)\n",
    "        y_batch = y.to(device=_DEVICE, non_blocking=True)\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(g_batch)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_pred_test += predicted.cpu().numpy().tolist()\n",
    "\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        minibatch_loss.append(loss.item())\n",
    "        y_probs_test = torch.cat((y_probs_test, outputs.data), 0)\n",
    "        y_true_test += y_batch.cpu().numpy().tolist()\n",
    "\n",
    "    # returning prob distribution over target classes, take softmax over the 1st dimension\n",
    "    y_probs_test = torch.nn.functional.softmax(y_probs_test, dim=1).cpu().numpy()\n",
    "    y_true_test = np.array(y_true_test)\n",
    "\n",
    "    # record training auroc and testing auroc\n",
    "    #auroc_train_history.append(roc_auc_score(y_true_train, y_probs_train[:, 1]))\n",
    "    #auroc_test_history.append(roc_auc_score(y_true_test, y_probs_test[:, 1]))\n",
    "\n",
    "    # record training balanced accuracy and testing balanced accuracy\n",
    "    balACC_train_history.append(balanced_accuracy_score(y_true_train, y_pred_train))\n",
    "    balACC_test_history.append(balanced_accuracy_score(y_true_test, y_pred_test))\n",
    "\n",
    "    # LOSS - epoch loss is defined as mean of minibatch losses within epoch\n",
    "    loss_train_history.append(np.mean(train_loss))\n",
    "    loss_test_history.append(np.mean(minibatch_loss))\n",
    "\n",
    "    # print the metrics\n",
    "    print(\"Train loss: {}, test loss: {}\".format(loss_train_history[-1], loss_test_history[-1]))\n",
    "    #print(\"Train AUC: {}, test AUC: {}\".format(auroc_train_history[-1], auroc_test_history[-1]))\n",
    "    print(\"Train Bal.ACC: {}, test Bal.ACC: {}\".format(balACC_train_history[-1], balACC_test_history[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bedda92429613c38dce8c018b5f564564fc8e6e3bd92ce59184d55779d13ad8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 ('tfm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
